{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShapeNet PointCloud Visualization\n",
    "- By running this script, you can get images of pointclouds.\n",
    "## To run this code...\n",
    "- You should prepare the summary file by running sample_and_summarize.py with a trained checkpoint.\n",
    "- You should install below libraries.\n",
    "    - matplotlib\n",
    "    - open3d\n",
    "    - numpy\n",
    "    - torch\n",
    "    - torchvision\n",
    "    - tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "#import open3d as o3d\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from draw import draw, draw_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories\n",
    "1. experiment_name: log_name.lstrip('gen/') in scripts\n",
    "2. save_dir: path to save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'images_attn'\n",
    "experiment_name = 'shapenet15k-airplane/n_samples_2000/'\n",
    "summary_name = os.path.join('/data/rna_rep_learning/nmsingh/scSet_ckpts/sample_complexity/', experiment_name, 'summary.pth')\n",
    "summary_train_name = os.path.join('/data/rna_rep_learning/nmsingh/scSet_ckpts/sample_complexity/', experiment_name, 'summary_train_recon.pth')\n",
    "\n",
    "imgdir = os.path.join(save_dir, experiment_name)\n",
    "imgdir_gt = os.path.join(imgdir, 'gt')\n",
    "imgdir_recon = os.path.join(imgdir, 'recon')\n",
    "imgdir_gen = os.path.join(imgdir, 'gen')\n",
    "imgdir_gt_train = os.path.join(imgdir, 'gt_train')\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(imgdir_gt, exist_ok=True)\n",
    "os.makedirs(imgdir_recon, exist_ok=True)\n",
    "os.makedirs(imgdir_gen, exist_ok=True)\n",
    "os.makedirs(imgdir_gt_train, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smp_set: torch.Size([405, 2500, 3])\n",
      "smp_mask: torch.Size([405, 2500])\n",
      "smp_att: 7\n",
      "priors: 8\n",
      "recon_set: torch.Size([405, 2500, 3])\n",
      "recon_mask: torch.Size([405, 2500])\n",
      "posteriors: 8\n",
      "dec_att: 7\n",
      "enc_att: 7\n",
      "enc_hiddens: 13\n",
      "gt_set: torch.Size([405, 2048, 3])\n",
      "gt_mask: torch.Size([405, 2048])\n",
      "mean: torch.Size([405, 1, 3])\n",
      "std: torch.Size([405, 1, 1])\n",
      "sid: 13\n",
      "mid: 13\n",
      "pid: 13\n",
      "cardinality: 13\n"
     ]
    }
   ],
   "source": [
    "summary = torch.load(summary_name)\n",
    "for k, v in summary.items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "summary_train = torch.load(summary_train_name)\n",
    "for k, v in summary_train.items():\n",
    "    try:\n",
    "        print(f\"{k}: {v.shape}\")\n",
    "    except AttributeError:\n",
    "        print(f\"{k}: {len(v)}\")\n",
    "len_att_train = len(summary_train['dec_att'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the samples to visualize\n",
    "- parse the samples by index.\n",
    "- below default code will visualize all samples. **Warning: Requires Huge Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_viz=10\n",
    "gen_targets=list(range(len(summary['smp_mask'])))[:n_viz]\n",
    "recon_targets=list(range(len(summary['gt_mask'])))[:n_viz]\n",
    "\n",
    "gen = summary['smp_set'][gen_targets]\n",
    "if 'smp_mask' in summary.keys():\n",
    "    gen_mask = summary['smp_mask'][gen_targets]\n",
    "else:\n",
    "    gen_mask = torch.zeros_like(gen)[:,:,0].bool()\n",
    "gt = summary['gt_set'][recon_targets]\n",
    "gt_mask = summary['gt_mask'][recon_targets]\n",
    "recon = summary['recon_set'][recon_targets]\n",
    "recon_mask = summary['recon_mask'][recon_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_targets_train = list(range(len(summary_train['gt_mask'])))[:n_viz]\n",
    "\n",
    "gt_train = summary_train['gt_set'][recon_targets_train]\n",
    "gt_mask_train = summary_train['gt_mask'][recon_targets_train]\n",
    "enc_att_train = [summary_train['enc_att'][l][:, :, recon_targets_train] for l in range(len_att_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(gt, gt_mask):\n",
    "    return draw_pointcloud(gt, gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(recon_targets)):\n\u001b[1;32m      3\u001b[0m     data_idx \u001b[39m=\u001b[39m recon_targets[idx]\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mnonzero(recon_imgs[idx]\u001b[39m.\u001b[39;49mmean(\u001b[39m0\u001b[39;49m) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSKIP\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Byte"
     ]
    }
   ],
   "source": [
    "recon_imgs = visualize(recon, recon_mask)\n",
    "for idx in range(len(recon_targets)):\n",
    "    data_idx = recon_targets[idx]\n",
    "    if torch.nonzero(recon_imgs[idx].float().mean(0) != 1).shape[0] == 0:\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "    pos_min = torch.nonzero(recon_imgs[idx].float().mean(0) != 1).min(0)[0]\n",
    "    pos_max = torch.nonzero(recon_imgs[idx].float().mean(0) != 1).max(0)[0]\n",
    "    recon_img = recon_imgs[idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "    save_image(recon_img.float(), os.path.join(imgdir_recon, f'{data_idx}.png'))\n",
    "del recon_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs = visualize(gt, gt_mask)\n",
    "for idx in range(len(recon_targets)):\n",
    "    data_idx = recon_targets[idx]\n",
    "    if torch.nonzero(gt_imgs[idx].mean(0) != 1).shape[0] == 0:\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "    pos_min = torch.nonzero(gt_imgs[idx].mean(0) != 1).min(0)[0]\n",
    "    pos_max = torch.nonzero(gt_imgs[idx].mean(0) != 1).max(0)[0]\n",
    "    gt_img = gt_imgs[idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "    save_image(gt_img, os.path.join(imgdir_gt, f'{data_idx}.png'))\n",
    "del gt_imgs\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = visualize(gen, gen_mask)\n",
    "for idx in range(len(gen_targets)):\n",
    "    if torch.nonzero(gen_imgs[idx].mean(0) != 1).shape[0] == 0:\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "    data_idx = gen_targets[idx]\n",
    "    pos_min = torch.nonzero(gen_imgs[idx].mean(0) != 1).min(0)[0]\n",
    "    pos_max = torch.nonzero(gen_imgs[idx].mean(0) != 1).max(0)[0]\n",
    "    gen_img = gen_imgs[idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "    save_image(gen_img.float(), os.path.join(imgdir_gen, f'{data_idx}.png'))\n",
    "del gen_imgs\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs = visualize(gt_train, gt_mask_train)\n",
    "for idx in range(len(recon_targets_train)):\n",
    "    data_idx = recon_targets_train[idx]\n",
    "    if torch.nonzero(gt_imgs[idx].mean(0) != 1).shape[0] == 0:\n",
    "        print(\"SKIP\")\n",
    "        continue\n",
    "    pos_min = torch.nonzero(gt_imgs[idx].mean(0) != 1).min(0)[0]\n",
    "    pos_max = torch.nonzero(gt_imgs[idx].mean(0) != 1).max(0)[0]\n",
    "    gt_img = gt_imgs[idx][:, pos_min[0]:pos_max[0]+1, pos_min[1]:pos_max[1]+1]\n",
    "    save_image(gt_img, os.path.join(imgdir_gt_train, f'{data_idx}.png'))\n",
    "del gt_imgs\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scset3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "30314d88031b0d7ffe696dc27ab20b7552f37a4dac8c459a5ad3e167b97b3a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
